<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Agente de voz</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #0f172a;
      color: #e5e7eb;
      margin: 0;
      padding: 2rem;
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
    }
    h1 {
      margin: 0;
      font-size: 1.8rem;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
    }
    #btnToggle {
      padding: 0.75rem 1.5rem;
      border-radius: 999px;
      border: none;
      font-size: 1rem;
      cursor: pointer;
      background: #22c55e;
      color: #022c22;
      font-weight: 600;
      box-shadow: 0 10px 25px rgba(34, 197, 94, 0.3);
      transition: transform 0.1s ease, box-shadow 0.1s ease, background 0.1s ease;
    }
    #btnToggle:hover {
      transform: translateY(-1px);
      box-shadow: 0 15px 30px rgba(34, 197, 94, 0.4);
      background: #16a34a;
    }
    #btnToggle.recording {
      background: #ef4444;
      color: #fee2e2;
      box-shadow: 0 10px 25px rgba(248, 113, 113, 0.3);
    }
    .conversation {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }
    .bubble {
      border-radius: 1rem;
      padding: 1rem;
      background: rgba(15, 23, 42, 0.85);
      border: 1px solid rgba(148, 163, 184, 0.3);
      min-height: 120px;
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
    }
    .bubble h2 {
      margin: 0;
      font-size: 0.9rem;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      color: #9ca3af;
    }
    .bubble p {
      margin: 0;
      font-size: 1rem;
      line-height: 1.5;
      color: #e5e7eb;
      white-space: pre-wrap;
    }
    .bubble.user {
      border-left: 3px solid #22c55e;
    }
    .bubble.agent {
      border-left: 3px solid #38bdf8;
    }
    details {
      margin-top: 1rem;
      font-size: 0.9rem;
      color: #9ca3af;
    }
    summary {
      cursor: pointer;
      margin-bottom: 0.5rem;
    }
    #log {
      background: #020617;
      border-radius: 0.5rem;
      padding: 0.75rem;
      max-height: 220px;
      overflow: auto;
      font-size: 0.8rem;
      border: 1px solid #1f2937;
      white-space: pre-wrap;
    }
    @media (max-width: 700px) {
      .conversation {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>Agente de voz</h1>
      <p style="margin-top:0.25rem; color:#9ca3af; font-size:0.9rem;">
        Pulsa <strong>Hablar</strong>, di algo (ej: “cuéntame un chiste corto”) y luego pulsa <strong>Parar</strong>.
      </p>
    </header>

    <button id="btnToggle">Hablar</button>

    <section class="conversation">
      <div class="bubble user">
        <h2>Tú dijiste</h2>
        <p id="userText">Aquí verás lo que el sistema entiende de tu voz.</p>
      </div>
      <div class="bubble agent">
        <h2>El agente responde</h2>
        <p id="agentText">Aquí verás la respuesta generada por la IA.</p>
      </div>
    </section>

    <details>
      <summary>Ver detalles técnicos (logs)</summary>
      <pre id="log"></pre>
    </details>
  </div>

<script>
  const btn = document.getElementById('btnToggle');
  const log = document.getElementById('log');
  const userTextEl = document.getElementById('userText');
  const agentTextEl = document.getElementById('agentText');

  let mediaRecorder;
  let socket;
  let isRecording = false;
  let audioChunks = [];

  // Historial de conversación para mandar al backend
  // Formato: [{ role: 'user'|'assistant', content: '...' }, ...]
  let conversationHistory = [];

  function addLog(msg) {
    log.textContent += msg + "\n";
    log.scrollTop = log.scrollHeight;
    console.log(msg);
  }

  async function startRecording() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      addLog("ERROR: getUserMedia NO disponible (necesitas HTTPS o localhost).");
      return;
    }

    try {
      addLog("Pidiendo permiso de micrófono...");
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false
        }
      });
      addLog("Permiso de micrófono CONCEDIDO.");

      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.onstart = () => {
        addLog("MediaRecorder iniciado");
      };

      mediaRecorder.ondataavailable = (e) => {
        addLog("Chunk de audio generado, tamaño: " + e.data.size);
        audioChunks.push(e.data);

        if (e.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
          e.data.arrayBuffer().then(buf => {
            addLog("Enviando chunk de audio al servidor (" + buf.byteLength + " bytes)");
            socket.send(buf);
          });
        }
      };

      mediaRecorder.onstop = async () => {
        addLog("MediaRecorder parado");

        if (audioChunks.length > 0) {
          const blob = new Blob(audioChunks, { type: 'audio/webm' });
          addLog("Audio total preparado para STT, tamaño: " + blob.size);

          const formData = new FormData();
          formData.append('audio', blob, 'grabacion.webm');
          // Adjuntamos historial al backend
          formData.append('history', JSON.stringify(conversationHistory));

          try {
            addLog("Enviando audio a /stt...");
            const resp = await fetch('/stt', {
              method: 'POST',
              body: formData
            });

            if (!resp.ok) {
              const errText = await resp.text();
              addLog("Error STT HTTP: " + resp.status + " - " + errText);
              return;
            }

            const data = await resp.json();

            // Mostrar claro en la UI
            if (data.transcript) {
              userTextEl.textContent = data.transcript;
              conversationHistory.push({ role: 'user', content: data.transcript });
            } else {
              userTextEl.textContent = '(no se ha entendido nada claro)';
            }

            if (data.answer) {
              agentTextEl.textContent = data.answer;
              conversationHistory.push({ role: 'assistant', content: data.answer });
            }

            // Limitar historial a los últimos 10 mensajes
            if (conversationHistory.length > 10) {
              conversationHistory = conversationHistory.slice(conversationHistory.length - 10);
            }

            addLog("Transcripción: " + (data.transcript || ''));
            addLog("Respuesta IA (texto): " + (data.answer || ''));

            if (data.audio) {
              try {
                addLog("Reproduciendo audio de respuesta...");
                const audioBytes = Uint8Array.from(atob(data.audio), c => c.charCodeAt(0));
                const audioBlob = new Blob([audioBytes], { type: 'audio/mpeg' });
                const url = URL.createObjectURL(audioBlob);
                const audio = new Audio(url);
                audio.play();
              } catch (e) {
                addLog("Error reproduciendo audio: " + e.message);
              }
            }
          } catch (err) {
            addLog("Error llamando a /stt: " + err.message);
          }
        }
      };

      mediaRecorder.start(500);
      isRecording = true;
      btn.textContent = 'Parar';
      btn.classList.add('recording');
    } catch (err) {
      addLog("ERROR al pedir el micrófono: " + err.name + " - " + err.message);
    }
  }

  btn.onclick = async () => {
    if (!isRecording) {
      const protocol = location.protocol === 'https:' ? 'wss' : 'ws';
      const wsUrl = `${protocol}://${location.host}`;
      addLog("Conectando WebSocket a: " + wsUrl);

      socket = new WebSocket(wsUrl);
      socket.binaryType = "arraybuffer";

      socket.onopen = () => {
        addLog("WS conectado");
        socket.send("TEST DESDE EL NAVEGADOR");
      };

      socket.onmessage = (event) => {
        addLog("Respuesta servidor: " + event.data);
      };

      socket.onclose = () => addLog("WS cerrado");
      socket.onerror = () => addLog("WS error");

      await startRecording();
    } else {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
      if (socket && socket.readyState === WebSocket.OPEN) {
        socket.close();
      }
      isRecording = false;
      btn.textContent = 'Hablar';
      btn.classList.remove('recording');
    }
  };
</script>

</body>
</html>
