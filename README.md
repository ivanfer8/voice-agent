# üéôÔ∏è Voice Agent Zener - Versi√≥n 2.0

Sistema de agente de voz conversacional con **streaming bidireccional en tiempo real** para agendamiento de citas de instalaci√≥n de fibra √≥ptica.

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquitectura](#arquitectura)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Modos de Operaci√≥n](#modos-de-operaci√≥n)
- [Despliegue](#despliegue)
- [Troubleshooting](#troubleshooting)
- [Roadmap](#roadmap)

---

## ‚ú® Caracter√≠sticas

### Modo Realtime (v2) üöÄ
- ‚úÖ **Streaming bidireccional**: Audio fluye en ambas direcciones simult√°neamente
- ‚úÖ **Latencia ultra-baja**: <500ms (vs 2-4s del modo legacy)
- ‚úÖ **Interrupciones naturales**: El usuario puede interrumpir al agente
- ‚úÖ **Detecci√≥n de voz avanzada**: VAD (Voice Activity Detection)
- ‚úÖ **Cancelaci√≥n inteligente**: El audio pendiente se cancela al interrumpir

### Modo Legacy (v1) üìû
- ‚úÖ **Compatibilidad total**: Mantiene funcionamiento actual
- ‚úÖ **Sin cambios en frontend**: UI actual funciona sin modificaciones
- ‚úÖ **Probado en producci√≥n**: Sistema estable y conocido

### Generales
- ‚úÖ **Arquitectura modular**: Componentes STT/LLM/TTS intercambiables
- ‚úÖ **Gesti√≥n de sesiones**: Historial conversacional persistente
- ‚úÖ **Logging profesional**: Logs estructurados con Pino
- ‚úÖ **M√©tricas de latencia**: Tracking de performance en tiempo real
- ‚úÖ **Health checks**: Monitoreo de estado del servicio
- ‚úÖ **Docker ready**: Despliegue con un comando

---

## üèóÔ∏è Arquitectura

### Stack Tecnol√≥gico

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND                         ‚îÇ
‚îÇ  - WebSocket bidireccional                          ‚îÇ
‚îÇ  - AudioContext API                                 ‚îÇ
‚îÇ  - MediaRecorder                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SERVIDOR NODE.JS                       ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ        SESSION MANAGER                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Historial conversacional                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Metadata de sesi√≥n                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Gesti√≥n de estado                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Deepgram ‚îÇ‚Üí ‚îÇ OpenAI   ‚îÇ‚Üí ‚îÇ  ElevenLabs WS  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   STT    ‚îÇ  ‚îÇ GPT-4o   ‚îÇ  ‚îÇ      TTS        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Streaming‚îÇ  ‚îÇ Streaming‚îÇ  ‚îÇ   Streaming     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ      AUDIO BUFFER MANAGER                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Sincronizaci√≥n                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Cancelaci√≥n en interrupciones             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principales

#### 1. **STT Module** (Speech-to-Text)
- **Proveedor**: Deepgram Nova 2
- **Latencia**: 100-200ms
- **Caracter√≠sticas**: Transcripci√≥n en espa√±ol, resultados parciales e interinos

#### 2. **LLM Module** (Language Model)
- **Proveedor**: OpenAI GPT-4o-mini
- **Latencia**: 200-400ms (primer token)
- **Caracter√≠sticas**: Streaming token-por-token, historial conversacional

#### 3. **TTS Module** (Text-to-Speech)
- **Proveedor**: ElevenLabs WebSocket
- **Modelo**: eleven_turbo_v2_5
- **Latencia**: 130-250ms
- **Caracter√≠sticas**: Streaming de audio, calidad superior

#### 4. **Session Manager**
- Gesti√≥n de sesiones activas
- Historial conversacional (√∫ltimos 15 mensajes)
- Limpieza autom√°tica de sesiones inactivas

#### 5. **Audio Buffer Manager**
- Gesti√≥n de colas de entrada/salida
- Cancelaci√≥n de audio en interrupciones
- Sincronizaci√≥n de streams

---

## üì¶ Requisitos

### Software
- **Node.js**: ‚â•20.0.0
- **npm**: ‚â•9.0.0
- **Docker**: ‚â•20.10 (opcional)

### APIs Requeridas
- **Deepgram API Key**: [https://deepgram.com](https://deepgram.com)
- **OpenAI API Key**: [https://platform.openai.com](https://platform.openai.com)
- **ElevenLabs API Key**: [https://elevenlabs.io](https://elevenlabs.io)
- **ElevenLabs Voice ID**: ID de la voz a utilizar

---

## üöÄ Instalaci√≥n

### 1. Clonar repositorio
```bash
git clone <tu-repo>
cd voice-agent-v2
```

### 2. Instalar dependencias
```bash
npm install
```

### 3. Configurar variables de entorno
```bash
cp .env.example .env
# Editar .env con tus API keys
```

### 4. Ejecutar en desarrollo
```bash
npm run dev
```

### 5. Ejecutar en producci√≥n
```bash
npm start
```

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno Principales

```bash
# Modo de operaci√≥n
ENABLE_REALTIME=false  # false = v1 (legacy), true = v2 (realtime)

# APIs (REQUERIDAS)
DEEPGRAM_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
ELEVENLABS_API_KEY=your_key_here
ELEVENLABS_VOICE_ID=your_voice_id_here

# Configuraci√≥n de audio
AUDIO_CHUNK_SIZE_MS=100        # Tama√±o de chunks (ms)
MAX_SILENCE_MS=1500            # Silencio m√°ximo antes de fin de frase
VAD_THRESHOLD_BYTES=500        # Umbral para detectar voz

# Sesiones
MAX_HISTORY_MESSAGES=15        # M√°ximo de mensajes en historial
SESSION_TIMEOUT_MS=1800000     # Timeout de sesi√≥n inactiva (30 min)

# Monitoring
ENABLE_METRICS=true            # Activar m√©tricas de latencia
DEBUG_AUDIO=false              # Logs detallados de audio
```

---

## üéÆ Uso

### Modo Legacy (v1)

**1. Configurar:**
```bash
ENABLE_REALTIME=false
```

**2. Endpoint:**
```
POST /stt
Content-Type: multipart/form-data

Form Data:
- audio: archivo de audio (webm)
- history: JSON string con historial
- clientName: nombre del cliente
- ttsProvider: "openai" | "elevenlabs"
```

**3. Respuesta:**
```json
{
  "transcript": "texto transcrito",
  "answer": "respuesta del agente",
  "audio": "base64_audio_mp3"
}
```

### Modo Realtime (v2)

**1. Configurar:**
```bash
ENABLE_REALTIME=true
```

**2. Conectar WebSocket:**
```javascript
const ws = new WebSocket('ws://localhost:3000/v2/voice');

// Enviar inicializaci√≥n
ws.send(JSON.stringify({
  type: 'init',
  metadata: {
    clientName: 'Iv√°n L√≥pez'
  }
}));

// Recibir eventos
ws.onmessage = (event) => {
  if (typeof event.data === 'string') {
    const message = JSON.parse(event.data);
    console.log('Evento:', message);
  } else {
    // Audio binario
    const audioChunk = event.data;
    // Reproducir...
  }
};

// Enviar audio
const audioBuffer = ...; // Buffer PCM16
ws.send(audioBuffer);
```

**3. Eventos del servidor:**
```javascript
// Sesi√≥n lista
{ type: 'event', event: 'ready', data: {...} }

// Transcripci√≥n parcial
{ type: 'event', event: 'transcript_partial', data: { text, confidence } }

// Transcripci√≥n final
{ type: 'event', event: 'transcript_final', data: { text, confidence } }

// Chunk de LLM
{ type: 'event', event: 'llm_chunk', data: { chunk } }

// Agente termin√≥ de hablar
{ type: 'event', event: 'agent_finished_speaking' }

// Interrupci√≥n procesada
{ type: 'event', event: 'interruption_processed' }

// Error
{ type: 'error', error: 'error_type', message: '...' }
```

---

## üîÑ Modos de Operaci√≥n

### Cambiar de modo Legacy a Realtime

**1. Actualizar .env:**
```bash
ENABLE_REALTIME=true
```

**2. Reiniciar servidor:**
```bash
npm restart
```

**3. Verificar:**
```bash
curl http://localhost:3000/health
```

Respuesta esperada:
```json
{
  "status": "ok",
  "mode": "realtime (v2)",
  ...
}
```

### Rollback a Legacy

**1. Actualizar .env:**
```bash
ENABLE_REALTIME=false
```

**2. Reiniciar servidor**

**No requiere cambios en frontend** - la UI actual sigue funcionando.

---

## üê≥ Despliegue

### Docker (Local)

```bash
# Build
docker build -t voice-agent-v2 .

# Run
docker run -d \
  --name voice-agent \
  -p 3000:3000 \
  --env-file .env \
  voice-agent-v2
```

### Docker Compose

```bash
# Iniciar
docker-compose up -d

# Ver logs
docker-compose logs -f voice-agent

# Parar
docker-compose down
```

### Dokploy

**1. Push a repositorio:**
```bash
git push origin feature/realtime-v2
```

**2. En Dokploy:**
- Crear nueva aplicaci√≥n o actualizar existente
- Seleccionar branch `feature/realtime-v2`
- Configurar variables de entorno
- Desplegar

**3. Variables en Dokploy:**
```
ENABLE_REALTIME=false  # Empezar con legacy
DEEPGRAM_API_KEY=...
OPENAI_API_KEY=...
ELEVENLABS_API_KEY=...
ELEVENLABS_VOICE_ID=...
```

**4. Cuando est√© listo, cambiar a realtime:**
```
ENABLE_REALTIME=true
```

---

## üêõ Troubleshooting

### Error: "Deepgram no est√° conectado"
- Verificar `DEEPGRAM_API_KEY` en `.env`
- Revisar logs: `docker-compose logs voice-agent`
- Verificar conectividad de red

### Error: "ElevenLabs WebSocket error"
- Verificar `ELEVENLABS_API_KEY` y `ELEVENLABS_VOICE_ID`
- Comprobar cuota de ElevenLabs
- Revisar logs detallados con `DEBUG_AUDIO=true`

### Alta latencia
- Verificar network latency: `ping api.deepgram.com`
- Revisar m√©tricas: endpoint `/info`
- Ajustar `AUDIO_CHUNK_SIZE_MS` (valor m√°s bajo = m√°s frecuencia)

### Sesiones no se limpian
- Verificar `SESSION_TIMEOUT_MS` en config
- Revisar logs de SessionManager
- Reiniciar servidor si es necesario

---

## üó∫Ô∏è Roadmap

### v2.1 (Pr√≥ximo)
- [ ] VAD (Voice Activity Detection) con Silero
- [ ] Soporte para Redis (sesiones distribuidas)
- [ ] Dashboard de m√©tricas en tiempo real
- [ ] Tests unitarios y de integraci√≥n

### v2.2 (Futuro)
- [ ] Soporte multi-idioma
- [ ] Integraci√≥n con CRM (creaci√≥n real de citas)
- [ ] Analytics avanzado (coste por llamada, tasa de conversi√≥n)
- [ ] Frontend v2 optimizado para streaming

### v3.0 (Long-term)
- [ ] Soporte para otros proveedores STT/TTS
- [ ] Modo h√≠brido (auto-switch seg√∫n latencia)
- [ ] Clustering y load balancing
- [ ] WebRTC nativo (sin WebSocket intermedio)

---

## üìä M√©tricas y Costes

### Latencia T√≠pica (Modo Realtime)
- STT (Deepgram): 100-200ms
- LLM (GPT-4o-mini): 200-400ms (primer token)
- TTS (ElevenLabs): 130-250ms
- **Total end-to-end**: ~430-850ms

### Coste por Minuto
- STT: $0.0043
- LLM: ~$0.002 (500 tokens)
- TTS: $0.018
- **Total**: ~$0.024/min ($1.44/hora)

**Comparado con VAPI**: $0.05-0.12/min ‚Üí **Ahorro: 50-80%**

---

## üë• Equipo

**Desarrollado por**: Zener Telecommunications  
**Versi√≥n**: 2.0.0  
**Fecha**: Diciembre 2024  

---

## üìÑ Licencia

Propietario - Zener Telecommunications

---

## üÜò Soporte

Para problemas o preguntas:
1. Revisar esta documentaci√≥n
2. Verificar logs: `docker-compose logs -f`
3. Consultar `/health` y `/info` endpoints
4. Contactar al equipo de desarrollo

---

**¬°Happy coding!** üöÄ
